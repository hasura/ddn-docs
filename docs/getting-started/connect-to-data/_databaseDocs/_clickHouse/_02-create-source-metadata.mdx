import BaseUrlLink from '@site/src/components/databaseDocs/baseLink';

## What's about to happen?

After initializing a connector and creating a JSON configuration, which represents our tables in ClickHouse, we can use
it to generate Hasura metadata. In the steps below, we'll utilize our `configuration.json` â€” populated by introspecting
our ClickHouse database â€” to create metadata which Hasura can use to construct our API.

## Step 1. Create the Hasura metadata

:::tip Required

- <BaseUrlLink to="/getting-started/prerequisites" text="The DDN CLI, VS Code extension, and Docker installed" />
- A new or existing <BaseUrlLink to="/getting-started/init-supergraph" text="supergraph" />
- A new or existing <BaseUrlLink to="/getting-started/init-subgraph" text="subgraph" />
- A <BaseUrlLink to="/getting-started/connect-to-data/connect-a-source" text="ClickHouse connector"/> initialized

:::

<!-- prettier-ignore -->
Hasura DDN uses a concept called "connector linking" to take [NDC-compliant](https://github.com/hasura/ndc-spec)
configuration JSON files for a data connector and transform them into an `hml` (Hasura Metadata Language) file as a <BaseUrlLink to="/supergraph-modeling/data-connectors/" text="DataConnectorLink" /> metadata object.

Basically, metadata objects in `hml` files define our API.

First we need to create this `hml` file with the `connector-link add` command and then convert our configuration files
into `hml` syntax and add it to this file with the `connector-link update` command.

Let's name the `hml` file the same as our connector, `my_clickhouse`:

```bash title="Run the following from the root of your project:"
ddn connector-link add my_clickhouse --subgraph my_subgraph
```

The new file is scaffolded out at `my_subgraph/metadata/my_clickhouse/my_clickhouse.hml`.

<details>
  <summary>Click here for an example `hml` `DataConnectorLink` file</summary>

```yaml title="my_clickhouse.hml"
kind: DataConnectorLink
version: v1
definition:
name: my_clickhouse
url:
  readWriteUrls:
    read:
      valueFromEnv: MY_SUBGRAPH_MY_CLICKHOUSE_READ_URL
    write:
      valueFromEnv: MY_SUBGRAPH_MY_CLICKHOUSE_WRITE_URL
schema:
  version: v0.1
  schema:
    scalar_types: {}
    object_types: {}
    collections: []
    functions: []
    procedures: []
  capabilities:
    version: ''
    capabilities:
      query: {}
      mutation: {}
```

</details>

The generated file has two environment variables â€” one for reads and one for writes â€” that you'll need to add to your
subgraph's `.env.my_subgraph` file. Each key is prefixed by the subgraph name, an underscore, and the name of the
connector. Ensure the port value matches what is published in your connector's docker compose file.

```env title="my_subgraph/.env.my_subgraph"
MY_SUBGRAPH_MY_CLICKHOUSE_READ_URL=http://local.hasura.dev:<port>
MY_SUBGRAPH_MY_CLICKHOUSE_WRITE_URL=http://local.hasura.dev:<port>
```

These values are for the ClickHouse connector itself and utilize `local.hasura.dev` to ensure proper resolution within
the docker container.

## Step 2. Start the connector's docker compose

Let's start our connector's docker compose file.

```bash title="Run the following from the connector's subdirectory inside a subgraph:"
docker compose -f docker-compose.my_clickhouse.yaml up
```

This starts our ClickHouse connector on the specified port. We can navigate to the following address, with the port
modified, to see the schema of our ClickHouse database:

```bash
http://localhost:<PORT>/schema
```

## Step 3. Include the connector in your docker compose

Kill the connector by pressing `CTRL+C` in the terminal tab in which the connector is running.

Then, add the following inclusion to the docker compose in your project's root directory, taking care to modify the
subgraph's name.

```yaml title="docker-compose.hasura.yaml"
include:
  - path: my_subgraph/connector/my_clickhouse/docker-compose.my_clickhouse.yaml
```

Now, whenever running the following, you'll bring up the GraphQL engine, observability tools, and any connectors you've
included:

```bash title="From the root of your project, run:"
HASURA_DDN_PAT=$(ddn auth print-pat) docker compose -f docker-compose.hasura.yaml watch
```

## Step 4. Update the new DataConnectorLink object

Finally, now that our `DataConnectorLink` has the correct environment variables configured for the ClickHouse connector,
we can run the update command to have the CLI look at the configuration JSON and transform it to reflect our database's
schema in `hml` format. In a new terminal tab, run:

```bash title="From the root of your project, run:"
ddn connector-link update my_clickhouse --subgraph my_subgraph
```

After this command runs, you can open your `my_subgraph/metadata/my_clickhouse.hml` file and see your metadata
completely scaffolded out for you ðŸŽ‰

## What did this do?

<!-- prettier-ignore -->
By creating a `my_clickhouse.hml` file, we've provided Hasura with a link between our original data source and the types which
we'll eventually expose via our API.

## Next steps

<!-- prettier-ignore -->
With a data connector fully configured, you can now start to create metadata for each table and view in your ClickHouse
database using `hml`. Learn how to do this by <BaseUrlLink to="/getting-started/connect-to-data/add-source-entities" text="exposing source entities" />.
