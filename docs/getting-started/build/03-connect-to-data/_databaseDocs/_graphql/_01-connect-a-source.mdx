import Thumbnail from "@site/src/components/Thumbnail";

## What's about to happen?

You can easily and quickly connect any GraphQL API to your supergraph.

To do this, we use the Hasura [GraphQL Native Data Connector](https://github.com/hasura/ndc-graphql) to facilitate the
connection.

<Thumbnail src="/img/get-started/ERD/connect-data.png" alt="Connect a data source" width="1000px" />

## Step 1. Initialize the GraphQL connector

:::tip Required

- [The DDN CLI, VS Code extension, and Docker installed](/getting-started/build/00-prerequisites.mdx)
- A new or existing [supergraph](/getting-started/build/01-init-supergraph.mdx)
- A new or existing [subgraph](/getting-started/build/02-init-subgraph.mdx)

:::

To initialize the GraphQL connector, run the following in your terminal:

```bash title="Run the following command:"
ddn connector init -i
```

- Select `hasura/graphql` from the list of connectors.
- Name it something descriptive. For this example, we'll call it `my_graphql`.
- Choose a port (press enter to accept the default recommended by the CLI).

:::tip Best practices

Importantly, a data connector can only connect to one data source.

The project will be kept organized with each data connector's configuration located in a relevant subgraph directory. In
this example the CLI will create a `my_subgraph/connector/my_graphql` directory if it doesn't exist. You can also change
this directory by passing a `--dir` flag to the CLI.

We recommend that the name of the connector and the directory in which the configuration is stored, `my_graphql` in this
example, should match for convenience and clarity sake for this tutorial, but it can be anything you want.

In subsequent steps, when running your connector locally, it's critical to ensure the port value matches the connection
string you provide in your subgraph's `.env.my_subgraph` file.

:::

### What did `connector init` do?

In the `my_subgraph/connector/my_graphql` directory which we specified in the command, the CLI created:

- A `connector.yaml` file which contains the local configuration for the connector.
- A `.hasura-connector` folder which contains the connector definition used to build and run it.
- A `compose.yaml` a file to run the MongoDB data connector locally in Docker.
- A placeholder `.ddnignore` file to prevent unnecessary files from being included in the build.
- A `configuration.json` that we'll update with values like our connection string(s) and any relevant headers.
- A `configuration.schema.json` that the connector will use generate your API.

In the `my_subgraph/metadata` directory, the CLI created:

- A `my_graphql.hml` file which contains the [`DataConnectorLink`](/supergraph-modeling/data-connector-links.mdx)
  metadata object which describes how the supergraph can interact with the connector.

Right now, the CLI has only scaffolded out configuration files for the data connector. Our connector still knows nothing
about the GraphQL schema. That's coming up in the next steps.

## Step 2. Configure the roles

### Step 2.1 Configure introspection

Under the `introspection` section, add the URL for your GraphQL endpoint.

```json title="Inside of my_subgraph/connector/my_graphql/configuration.json:"
{
  ...
  "introspection": {
    "endpoint": {
      //highlight-start
      "value": "https://my-graphql-endpoint/graphql"
      //highlight-end
    }
  }
}
```

:::tip Connecting to an Existing Hasura v2 Instance

When connecting to an existing Hasura v2 instance, it is important to update the configuration introspection with the
appropriate headers: `x-hasura-admin-secret` and `x-hasura-role`. These headers are necessary for executing
introspection requests successfully.

You may want to set a pre-defined value for `x-hasura-role` to ensure that introspection occurs under a specific role.
This can be particularly useful if you want requests to be executed without requiring forwarded authentication
credentials.

**Caution:** If no explicit role is set, the admin role will be used to fetch the schema. This may not be suitable for
your application.

There are some other considerations for connecting to a v2 instance. For more details, please visit
[the connector's repository](https://github.com/hasura/ndc-graphql).

:::

### Step 2.2 Configure execution

Under the `execution` section, add the URL for your GraphQL endpoint.

```json title="Inside of my_subgraph/connector/my_graphql/configuration.json:"
{
  ...
  "execution": {
    "endpoint": {
      //highlight-start
      "value": "https://my-graphql-endpoint/graphql"
      //highlight-end
    }
  }
}
```

## Step 3. Introspect your GraphQL API

This will start the connector using the `compose.yaml` in its directory, and then introspect your GraphQL API and fetch
all the required information for your connector.

```bash
ddn connector introspect my_graphql
```

:::tip Remove placeholder environment variables

If your API doesn't have authorization, or if you haven't set `GRAPHQL_ENDPOINT_AUTHORIZATION`, remove these values from
your config. Otherwise, introspection will fail.

:::

## What did `connector introspect` do?

The CLI will introspect the GraphQL schema and create a `schema.graphql` file in the `my_subgraph/connector/my_graphql`
directory. This schema is a representation of your external GraphQL API.

Additionally, the CLI updated the `DataConnectorLink` object with the latest metadata to interact with the connector.

:::tip o11y via OpenTelemetry

Yes! Connectors ship with OTEL-enabled tracing available, out of the box ðŸŽ‰

:::

## Step 4. Track your types

Types exposed by your GraphQL API are represented as [Models](/supergraph-modeling/models.mdx) and
[Commands](/supergraph-modeling/commands.mdx) in your API. The next command we'll run will take each type in your
GraphQL schema and create an `hml` file for it. These files will then be used by the Hasura engine to generate your API.

```bash title="Run the following to create your models and commands:"
ddn connector-link add-resources my_graphql
```

## Step 4. Create a new build and restart the services

To reflect the changes in your API, create a new build.

```bash title= "Run the following:"
ddn supergraph build local
```

And, if your services are not already running, start them.

```bash title="Run the following:"
HASURA_DDN_PAT=$(ddn auth print-pat) docker compose --env-file .env up --build --watch
```

You should see your models available in your API by opening your console using `ddn console --local` ðŸŽ‰

## Next steps

With our data source connected and all of our models tracked, we can move on to
[add custom authorization rules](/getting-started/build/05-add-permissions.mdx) using permissions,
[incorporate custom business logic](/getting-started/build/06-add-business-logic.mdx), or
[create relationships](/getting-started/build/07-create-a-relationship.mdx) across data sources!
