## What's about to happen?

After initializing a connector and creating a JSON configuration, which represents our tables in PostgreSQL, we can use
it to generate Hasura metadata. In the steps below, we'll utilize our `configuration.json` (populated by introspecting
our PostgreSQL database) to create metadata which Hasura can use to construct our API.

## Step 1. Create the Hasura metadata

:::tip Required

- [The DDN CLI, VS Code extension, and Docker installed](/getting-started/build/00-prerequisites.mdx)
- A new or existing [supergraph](/getting-started/build/01-init-supergraph.mdx)
- A new or existing [subgraph](/getting-started/build/02-init-subgraph.mdx)
- A [PostgreSQL connector](/getting-started/build/03-connect-to-data/01-connect-a-source.mdx) initialized,
introspected and running in Docker.

:::

Hasura DDN uses a concept called "connector linking" to take configuration JSON files for a data connector and
transform them into an `hml` (Hasura Metadata Language) file as a
[`DataConnectorLink`](/supergraph-modeling/data-connector-links.mdx) metadata object which describes our data source.

Let's add and name the `hml` file the same as our connector, `my_pg`:

```bash title="Run the following from the root of your project:"
ddn connector-link add my_pg \
  --subgraph my_subgraph/subgraph.yaml \
  --configure-host http://local.hasura.dev:8085 \
  --target-env-file my_subgraph/.env.my_subgraph.local
```

The new file is scaffolded out at `my_subgraph/metadata/my_pg.hml`.

:::info JSON and HML, why both?

Basically, metadata objects in `hml` files contain the data connector schema in a
[format](https://github.com/hasura/ndc-spec) which is generic for all connectors. The JSON on the other hand contains a
format specific to that connector. It does not need to be JSON, it could just as easily be SQL files, TypeScript
functions, or anything else. It's just a representation that the specific connector understands.

:::

<details>
  <summary>Click here for an example `hml` `DataConnectorLink` file</summary>

```yaml title="my_pg.hml"
kind: DataConnectorLink
version: v1
definition:
  name: my_pg
  url:
    readWriteUrls:
      read:
        valueFromEnv: MY_SUBGRAPH_MY_PG_READ_URL
      write:
        valueFromEnv: MY_SUBGRAPH_MY_PG_WRITE_URL
  schema:
    version: v0.1
    schema:
      scalar_types: {}
      object_types: {}
      collections: []
      functions: []
      procedures: []
    capabilities:
      version: ""
      capabilities:
        query: {}
        mutation: {}
```

</details>

The generated file has two environment variables â€” one for reads and one for writes. Because we used the convenience
flag: `--configure-host` on the command, these keys are already set in the `.env.my_subgraph.local` file:

```env title="my_subgraph/.env.my_subgraph"
MY_SUBGRAPH_MY_PG_READ_URL="http://local.hasura.dev:8085"
MY_SUBGRAPH_MY_PG_WRITE_URL="http://local.hasura.dev:8085"
```

These values are for the PostgreSQL connector itself and utilize `local.hasura.dev` to ensure proper resolution within
the docker container.

## Step 2. Update the new DataConnectorLink object with metadata for your PostgreSQL database

Finally, now that our `DataConnectorLink` has the correct environment variables configured for the PostgreSQL connector,
we can run the `update` command to have the CLI look at the configuration JSON and transform it to reflect our
database's schema in `hml` format. In a new terminal tab, run:

```bash title="From the root of your project, run:"
ddn connector-link update my_pg \
  --subgraph my_subgraph/subgraph.yaml \
  --env-file my_subgraph/.env.my_subgraph.local
```

After this command runs, you can open your `my_subgraph/metadata/my_pg.hml` file and see your metadata completely
scaffolded out for you ðŸŽ‰

## What did this do?

By creating a `my_pg.hml` file, we've provided Hasura with a link between our original data source and the types which
we'll eventually expose via our API.

## Next steps

With a data connector fully configured, you can now start to create metadata for each table and view in your PostgreSQL
database using `hml`. Learn how to do this by
[exposing source entities](/getting-started/build/03-connect-to-data/03-add-source-entities.mdx).
