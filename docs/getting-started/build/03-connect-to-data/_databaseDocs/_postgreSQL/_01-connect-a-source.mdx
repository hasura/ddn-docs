import Thumbnail from "@site/src/components/Thumbnail";

## What's about to happen?

We want to connect our [PostgreSQL](https://www.postgresql.org/) database to our API. To do this, we use the Hasura
PostgreSQL data connector to facilitate the connection and then introspect the database to generate JSON which the
Hasura CLI will then use to create metadata which can then define your API.

<Thumbnail src="/img/get-started/ERD/connect-data.png" alt="Connect a data source" width="1000px" />

## Step 1. Init the PostgreSQL connector

:::tip Required

- [The DDN CLI, VS Code extension, and Docker installed](/getting-started/build/00-prerequisites.mdx)
- A new or existing [supergraph](/getting-started/build/01-init-supergraph.mdx)
- A new or existing [subgraph](/getting-started/build/02-init-subgraph.mdx)

:::

To initialize the PostgreSQL connector, run the following in your terminal.

```bash title="From the root of your project, run:"
ddn connector init my_pg \
  --subgraph my_subgraph/subgraph.yaml \
  --hub-connector hasura/postgres \
  --configure-port 8082 \
  --add-to-compose-file compose.yaml
```

With this `connector init` command, we're passing a few important values.

**Connector name**

We're naming the connector `my_pg` in this example, but you can call it whatever makes sense to you. For example, if
this connector is integrating a database all about product metadata, it would make sense to name it something like
`product_metadata_postgres_connector`.

**Subgraph: `--subgraph`**

We're specifying the subgraph config file that this connector will be added to using the `--subgraph` flag.

**Connector: `--hub-connector`**

We're specifying that this connector should be the `hasura/postgres` connector listed in the
[Connector Hub](https://hasura.io/connectors/postgres).

**Port: `configure-port`**

We're specifying the port to run the connector on. This is important to avoid port collisions with other connectors or
services which you might have running on your machine. Remember to use a different port for each connector you may have
running.

**Compose file: `--add-to-compose-file`**

We're specifying the `--add-to-compose-file` flag to add the connector's **own** Docker compose file to the main
`compose.yaml` file. This is for convenience and allows us to start the Hasura Engine and connectors together.

:::tip Best practices

Importantly, a data connector can only connect to one data source.

The project will be kept organized with each data connector's configuration located in a relevant subgraph directory. In
this example the CLI will create a `my_subgraph/connector/my_pg` directory if it doesn't exist. You can also change this
directory by passing a `--dir` flag to the CLI.

We recommend that the name of the connector and the directory in which the configuration is stored, `my_pg` in this
example, should match for convenience and clarity sake for this tutorial, but it can be anything you want.

In subsequent steps, when running your connector locally, it's critical to ensure the port value matches the connection
string you provide in your subgraph's `.env.my_subgraph.local` file.

:::

### What did `connector init` do?

In the `my_subgraph/connector/my_pg` directory which we specified in the command, the CLI created:

- A `connector.local.yaml` file which contains the local configuration for the connector.
- A `connector.cloud.yaml` file which contains the cloud configuration for the connector.
- A `.hasura-connector` folder which contains the connector definition used to build and run it.
- A `compose.yaml` a file to run the PostgreSQL data connector locally in Docker.
- A placeholder `.ddnignore` file to prevent unnecessary files from being included in the build.
- An `.env.local` file for environment variables for pertaining to running this connector locally.
- An `.env.cloud` file for environment variables for pertaining to running this connector in the cloud.
- A `configuration.json` file which contains configuration for the data connector itself.
- A `schema.json` file which is the JSON schema that `configuration.json` follows. This is to enable autocomplete in VS
  Code.

Right now, the CLI has only scaffolded out configuration files for the data connector. Our connector still knows nothing
about the PostgreSQL database or the data it contains. That's coming up in the next steps.

## Step 2. Update the connection URI

The PostgreSQL connector ships with a sample read-only database connection as the default `CONNECTION_URI`.

The CLI provides an `.env.local` file for our connector in the `my_subgraph/connector/my_pg` directory. **If you wish to
override the default demo connection, you can update the key-value pair of `CONNECTION_URI` with your custom connection
string to this file.**

```env title="my_subgraph/connector/my_pg/.env.local"
OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=http://local.hasura.dev:4317
OTEL_SERVICE_NAME=my_subgraph_my_pg
#highlight-start
CONNECTION_URI=<your-custom-postgres-connection-uri>
#highlight-end
```

You can use a local PostgreSQL database or a cloud-hosted option. If you already have one you can connect to, you can go
ahead and do that using the steps above. Hasura DDN will not modify your database in any way, so you can use an existing
database without any worries.

:::info Environment-specific caveats

**Local PostgreSQL**

If you're using a local PostgreSQL database — such as through [Docker](https://hub.docker.com/_/postgres) — you can
connect to it directly from the data connector. However, if you deploy your connector to Hasura DDN, the cloud-hosted
version of your data connector won't be able to find your local database. You'll need to use a tool like
[ngrok](https://ngrok.com/) to provide a tunnel to access your database from the cloud. This will expose the port, most
likely `5432`, on which the database is running and allow Hasura DDN to connect to it.

**Cloud-hosted PostgreSQL**

Alternatively, if you have a cloud-hosted database, as Hasura DDN will need to reach your database, ensure you've
allowlisted `0.0.0.0/0` (for now) so that DDN is able to reach it.

:::

## Step 3. Introspect your database

With the connector configured, we can now use the CLI to introspect our PostgreSQL database and create a data connector
specific configuration file. This configuration file, which describes the schema of our PostgreSQL database, will then
be used in a later step to generate Hasura metadata which describes our API.

```bash title="From the root of your project run:"
ddn connector introspect --connector my_subgraph/connector/my_pg/connector.local.yaml
```

## What did `connector introspect` do?

The command introspected your data source to create a JSON configuration file.

If you look at the `configuration.json` for your connector, you'll see metadata describing your PostgreSQL schema in a
format which the connector specifies.

:::tip Initialize a Git repository

At this point, we recommend initializing a Git repository. This gives you a fallback point as you begin to iterate on
your project.

:::

## Step 4. Restart the services

Let's restart our docker compose services so that Docker can create a PostgreSQL connector build for us now that we've
added and introspected the connector. **If you have existing services running, bring them down using
`docker compose down` or `CTRL` + `C` if your terminal tab is still actively logging information.**

```bash title="From the root of your project, run:"
HASURA_DDN_PAT=$(ddn auth print-pat) docker compose up --build --watch
```

This starts our Hasura Engine, observability tools and the PostgreSQL connector all together since we added the
connector's Docker compose file to the main `compose.yaml` file using the `--add-to-compose-file` flag when we
initialized the connector. `HASURA_DDN_PAT=$(ddn auth print-pat)` gives the Hasura Engine access to the DDN CLI's
authentication token.

We can navigate to the following address, with the port modified, to see the schema of our PostgreSQL database:

```text
http://localhost:8082/schema
```

## Next steps

With this JSON configuration, which represents the tables in PostgreSQL, we can now use it to
[generate Hasura metadata](/getting-started/build/03-connect-to-data/02-create-source-metadata.mdx).
