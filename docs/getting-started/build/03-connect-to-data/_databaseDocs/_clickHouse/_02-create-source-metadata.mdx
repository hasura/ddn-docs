## What's about to happen?

After initializing a ClickHouse connector and creating a JSON configuration, which represents our tables in a format
which the connector specifies, we can use it to generate Hasura metadata. In the steps below, we'll utilize our
`configuration.json` â€” populated by introspecting our ClickHouse database â€” to create metadata which Hasura can use to
construct our API.

## Step 1. Create the Hasura metadata

:::tip Required

- [The DDN CLI, VS Code extension, and Docker installed](/getting-started/build/00-prerequisites.mdx)
- A new or existing [supergraph](/getting-started/build/01-init-supergraph.mdx)
- A new or existing [subgraph](/getting-started/build/02-init-subgraph.mdx)
- A [ClickHouse connector](/getting-started/build/03-connect-to-data/01-connect-a-source.mdx) initialized and
introspected

:::

Hasura DDN uses a concept called "connector linking" to take configuration JSON files for a data connector and
transform them into an `hml` (Hasura Metadata Language) file as a
[`DataConnectorLink`](/supergraph-modeling/data-connector-links/) metadata object which describes our data source.

Let's add and name the `hml` file the same as our connector, `my_clickhouse`:

```bash title="Run the following from the root of your project:"
ddn connector-link add my_clickhouse \
  --subgraph my_subgraph/subgraph.yaml \
  --configure-host http://local.hasura.dev:8082 \
  --target-env-file my_subgraph/.env.my_subgraph.local
```

The new file is scaffolded out at `my_subgraph/metadata/my_mongo.hml`.

:::info JSON and HML, why both?

Basically, metadata objects in `hml` files contain the data connector schema in a
[format](https://github.com/hasura/ndc-spec) which is generic for all connectors. The JSON on the other hand contains a
format specific to that connector. It does not need to be JSON, it could just as easily be SQL files, TypeScript
functions, or anything else. It's just a representation that the specific connector understands.

:::

<details>
  <summary>Click here for an example `hml` `DataConnectorLink` file</summary>

```yaml title="my_clickhouse.hml"
kind: DataConnectorLink
version: v1
definition:
name: my_clickhouse
url:
  readWriteUrls:
    read:
      valueFromEnv: MY_SUBGRAPH_MY_CLICKHOUSE_READ_URL
    write:
      valueFromEnv: MY_SUBGRAPH_MY_CLICKHOUSE_WRITE_URL
schema:
  version: v0.1
  schema:
    scalar_types: {}
    object_types: {}
    collections: []
    functions: []
    procedures: []
  capabilities:
    version: ""
    capabilities:
      query: {}
      mutation: {}
```

</details>

The generated file has two environment variables â€” one for reads and one for writes. Because we used the convenience
flag: `--configure-host` on the command, these values are already set in the `.env.my_subgraph.local` file:

```env title="my_subgraph/.env.my_subgraph"
MY_SUBGRAPH_MY_CLICKHOUSE_READ_URL=http://local.hasura.dev:8082
MY_SUBGRAPH_MY_CLICKHOUSE_WRITE_URL=http://local.hasura.dev:8082
```

These values are for the ClickHouse connector itself and utilize `local.hasura.dev` to ensure proper resolution within
the docker container.

## Step 2. Start the services

Let's start our docker compose services if they are not already running.

```bash title="From the root of your project, run:"
HASURA_DDN_PAT=$(ddn auth print-pat) docker compose up --build --watch
```

This starts our Hasura Engine, observability tools and the ClickHouse connector all together since we added the
connector's Docker compose file to the main `compose.yaml` file using the `--add-to-compose-file` flag
when we initialized the connector. `HASURA_DDN_PAT=$(ddn auth print-pat)` gives the Hasura Engine access to the DDN
CLI's authentication token.

We can navigate to the following address, with the port modified, to see the schema of our ClickHouse database:

```text
http://localhost:8082/schema
```

## Step 3. Update the new DataConnectorLink object with metadata for your ClickHouse database

Finally, now that our `DataConnectorLink` has the correct environment variables configured for the ClickHouse connector,
we can run the `update` command to have the CLI look at the configuration JSON and transform it to reflect our
database's schema in `hml` format. In a new terminal tab, run:

```bash title="From the root of your project, run:"
ddn connector-link update my_clickhouse \
  --subgraph my_subgraph/subgraph.yaml \
  --env-file my_subgraph/.env.my_subgraph.local
```

After this command runs, you can open your `my_subgraph/metadata/my_clickhouse.hml` file and see your metadata
completely scaffolded out for you ðŸŽ‰

## What did this do?

By creating a `my_clickhouse.hml` file, we've provided Hasura with a link between our original data source and the
types which we'll eventually expose via our API.

## Next steps

With a data connector fully configured, you can now start to create metadata for each table and view in your ClickHouse
database using `hml`. Learn how to do this by
[exposing source entities](/getting-started/build/03-connect-to-data/03-add-source-entities.mdx).
