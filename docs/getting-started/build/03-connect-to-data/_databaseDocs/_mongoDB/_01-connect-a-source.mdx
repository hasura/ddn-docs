import Thumbnail from "@site/src/components/Thumbnail";

## What's about to happen?

We want to connect our [MongoDB](https://www.mongodb.com/) database to our API. To do this, we use the Hasura MongoDB
data connector to facilitate the connection and then introspect the database to generate JSON which the Hasura CLI will
then use to create metadata which can then define your API.

<Thumbnail src="/img/get-started/ERD/connect-data.png" alt="Connect a data source" width="1000px" />

## Step 1. Initialize the MongoDB connector

:::tip Required

- [The DDN CLI, VS Code extension, and Docker installed](/getting-started/build/00-prerequisites.mdx)
- A new or existing [supergraph](/getting-started/build/01-init-supergraph.mdx)
- A new or existing [subgraph](/getting-started/build/02-init-subgraph.mdx)

:::

To initialize the MongoDB connector, run the following in your terminal:

```bash
ddn connector init my_mongo \
  --hub-connector hasura/mongodb \
  --configure-port 8083 \
  --add-to-compose-file compose.yaml
```

With this `connector init` command, we're passing a few important values.

**Connector name**

We're naming the connector `my_mongo` in this example, but you can call it whatever makes sense to you. For example, if
this connector is integrating a database all about product metadata, it would make sense to name it something like
`product_metadata_mongodb_connector`.

**Subgraph: `--subgraph`**

We're specifying the subgraph config file that this connector will be added to using the `--subgraph` flag.

**Connector: --hub-connector**

We're specifying that this connector should be the `hasura/mongodb` connector listed in the
[Connector Hub](https://hasura.io/connectors/mongodb).

**Port: `configure-port`**

We're specifying the port to run the connector on. This is important to avoid port collisions with other connectors or
services which you might have running on your machine. Remember to use a different port for each connector you may have
running.

**Compose file: `--add-to-compose-file`**

We're specifying the `--add-to-compose-file` flag to add the connector's **own** Docker compose file to the main
`compose.yaml` file. This is for convenience and allows us to start the Hasura Engine and connectors together.

:::tip Best practices

Importantly, a data connector can only connect to one data source.

The project will be kept organized with each data connector's configuration located in a relevant subgraph directory. In
this example the CLI will create a `my_subgraph/connector/my_mongo` directory if it doesn't exist. You can also change
this directory by passing a `--dir` flag to the CLI.

We recommend that the name of the connector and the directory in which the configuration is stored, `my_mongo` in this
example, should match for convenience and clarity sake.

In subsequent steps, when running your connector locally, it's critical to ensure the port value matches the connection
string you provide in your subgraph's `.env.my_subgraph.local` file.

:::

### What did `connector init` do?

In the `my_subgraph/connector/my_mongo` directory which we specified in the command, the CLI created:

- A `connector.local.yaml` file which contains the local configuration for the connector.
- A `connector.cloud.yaml` file which contains the cloud configuration for the connector.
- A `.hasura-connector` folder which contains the connector definition used to build and run it.
- A `compose.yaml` a file to run the MongoDB data connector locally in Docker.
- A placeholder `.ddnignore` file to prevent unnecessary files from being included in the build.
- An `.env.local` file for environment variables for pertaining to running this connector locally.
- An `.env.cloud` file for environment variables for pertaining to running this connector in the cloud.

Right now, the CLI has only scaffolded out configuration files for the data connector. Our connector still knows nothing
about the MongoDB database or the data it contains. That's coming up in the next steps.

## Step 2. Add the MongoDB connection URI

Now that our MongoDB data connector has been scaffolded out for us, we need to provide a **connection string** so that
we can connect to it. To do this we'll first need a MongoDB database to connect to.

The CLI has provided an `.env.local` file for our connector. We can add a key-value pair of `MONGODB_DATABASE_URI` along
with the connection string itself to this file and our connector will use this to connect to our MongoDB database. The
file, after adding the `MONGODB_DATABASE_URI` should look like this example:

```env title="In the .env.local file for the connector"
OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=http://local.hasura.dev:4317
OTEL_SERVICE_NAME=my_mongo
MONGODB_DATABASE_URI="mongodb+srv://<your-mongodb-connection-string>"
```

:::tip Need a connection string?

Feel free to use this read-only MongoDB connection string for testing purposes:

```text
mongodb+srv://read_only_user:readonlyuser@v3-docs-sample-app.vh2tp.mongodb.net/sample_mflix?retryWrites=true&w=majority&appName=v3-docs-sample-app
```

:::

Remember to use quotes as the string will likely have some characters which will break the `.env` file if not enclosed.

This value is already referenced in the scaffolded out
`my_subgraph/connector/my_mongo/hasura-connector/connector-metadata.yaml` file. Eg:

```yaml
---
supportedEnvironmentVariables:
  - name: MONGODB_DATABASE_URI
  description: The URI for the MongoDB database
```

You can use a local MongoDB database, or a cloud-hosted one like MongoDB Atlas. Check out
[this page](https://www.mongodb.com/docs/manual/installation/) for a list of options for running a MongoDB database if
you don't already have one. If you already have one you can connect to, you can go ahead and do that. Hasura DDN will
not modify your database in any way, so you can use an existing database without any worries.

:::tip Docker networking Inside a Docker container

`local.hasura.dev` is set to the `host-gateway` alias in the `extra_hosts` option. With this option set,
`local.hasura.dev` resolves to the host machine's gateway IP address from _inside_ the container. This allows various
containers, such as the GraphQL Engine and data connectors, to communicate with each other and out the host machine.

:::

:::info Environment-specific caveats

**Local Mongo**

If you're using a local MongoDB database â€” such as through [Docker](https://hub.docker.com/_/mongodb) â€” you can connect
to it directly from the data connector. However, if you deploy your supergraph to Hasura DDN the cloud-hosted version of
your data connector won't be able to find your database. So tunneling that connection from the start with a tool like
[ngrok](https://ngrok.com/) is a good idea.

**Cloud-hosted MongoDB**

Alternatively, if you have a cloud-hosted database, perhaps with
[MongoDB Atlas](https://www.mongodb.com/products/platform/atlas-database) as Hasura DDN will need to reach your
database, ensure you've allowlisted `0.0.0.0/0` (for now) so that DDN is able to reach it. To learn how to deploy a
MongoDB Atlas cluster, see the [official documentation](https://www.mongodb.com/docs/atlas/getting-started/).

:::

## Step 3. Introspect your database

With the connector configured, we can now use the CLI to introspect our MongoDB database to create a source-specific
configuration file for our connector:

```bash
ddn connector introspect --connector my_subgraph/connector/my_mongo/connector.local.yaml
```

## What did `connector introspect` do?

We specify the connector (and by proxy, the data source) that we want to introspect with the `--connector` flag and
provide it with the location of that `connector.yaml` configuration file.

The CLI will introspect the MongoDB database and generate a few new files in the `connector/my_mongo/` directory.

These include a `configuration.json` file and a new `schema` directory with a definition of all collections found in
MongoDB in a JSON [NDC-compliant](https://github.com/hasura/ndc-spec) format which the connector specifies.

Eg:

```text
.
â”œâ”€â”€ comments.json
â”œâ”€â”€ embedded_movies.json
â”œâ”€â”€ movies.json
â”œâ”€â”€ sessions.json
â”œâ”€â”€ theaters.json
â””â”€â”€ users.json
```

:::tip o11y via OpenTelemetry

Yes! Connectors ship with OTEL-enabled tracing available, out of the box ðŸŽ‰

:::

## Step 4. Restart the services

Let's restart our docker compose services so that Docker can create a MongoDB connector build for us now that we've
added and introspected the connector. **If you have existing services running, bring them down using
`docker compose down` or `CTRL` + `C` if your terminal tab is still actively logging information.**

```bash title="Run:"
HASURA_DDN_PAT=$(ddn auth print-pat) docker compose up --build --watch
```

This starts our Hasura Engine, observability tools and the MongoDB connector all together since we added the connector's
Docker compose file to the main `compose.yaml` file using the `--add-to-compose-file` flag when we initialized the
connector. `HASURA_DDN_PAT=$(ddn auth print-pat)` gives the Hasura Engine access to the DDN CLI's authentication token.

We can navigate to the following address, with the port modified, to see the schema of our MongoDB database:

```text
http://localhost:8083/schema
```

## Next steps

With this JSON configuration, which represents the collections in MongoDB, we can now use it to
[generate Hasura metadata](/getting-started/build/03-connect-to-data/02-create-source-metadata.mdx).
