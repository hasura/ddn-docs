import Thumbnail from "@site/src/components/Thumbnail";

## What's about to happen?

With Hasura, you can integrate — and even host — business logic directly with Hasura DDN and your API.

You can handle custom business logic using the Python Lambda connector. Using this connector, you can transform or
enrich data before it reaches your consumers, or perform any other app business logic you may need.

You can then integrate these functions as individual [**commands**](/supergraph-modeling/commands.mdx) in your metadata
and resulting API. This process simplifies client applications and speeds up your backend development.

<Thumbnail src="/img/get-started/ERD/add-bizlogic.png" alt="Add business logic to your API" width="1000px" />

## Steps

:::tip Required

- [The DDN CLI, VS Code extension, and Docker installed](/getting-started/build/00-prerequisites.mdx)
- A new or existing [project](/getting-started/deployment/01-create-a-project.mdx)
- At least one [subgraph](/getting-started/build/02-init-subgraph.mdx)
- [Python](https://www.python.org/downloads/) version `>=3.11`

:::

In this guide we will:

- Initialize the `hasura/python` data connector
- Use Python and pip to create a simple script
- Add a new `DataConnectorLink`
- Update the `DataConnectorLink` to track the function script as a command in our metadata
- Create a new API build and test it

### Step 1. Initialize the Python Lambda connector

Let's begin by initializing the connector on our project. In the example below, you'll see some familiar flags with new
values being passed to them. We'll call this `my_python` and use the `hasura/python` connector from the connector hub:

```bash title="Run the following command:"
ddn connector init -i
```

- Select `hasura/python` from the list of connectors.
- Name it something descriptive. For this example, we'll call it `my_python`.
- Choose a port (press enter to accept the default recommended by the CLI).

:::tip Best practices

Importantly, a data connector can only connect to one data source.

The project will be kept organized with each data connector's configuration located in a relevant subgraph directory. In
this example the CLI will create a `my_subgraph/connector/my_python` directory if it doesn't exist. You can also change
this directory by passing a `--dir` flag to the CLI.

We recommend that the name of the connector and the directory in which the configuration is stored, `my_python` in this
example, should match for convenience and clarity sake.

In subsequent steps, when running your connector locally, it's critical to ensure the port value matches the connection
string you provide in your subgraph's `.env.my_subgraph` file.

:::

#### What did this do?

This command created the following file structure in a `my_subgraph/connector/my_python` directory, with the
`functions.py` file being your connector's entrypoint:

```bash
.
├── .ddnignore
├── .env.cloud
├── .env.local
├── .gitignore
├── .hasura-connector
│  ├── ...
├── compose.yaml
├── connector.yaml
# highlight-start
├── functions.py
# highlight-end
└── requirements.txt
```

### Step 2. Install pip package dependencies

Let's install any necessary dependencies:

```bash title="Change to the connector directory and install dependencies:"
cd my_subgraph/connector/my_python && pip3 install -r requirements.txt
```

### Step 3. Run the connector

Then, from the `my_python` directory run this command to load environment variables from the `.env` file, and start
the connector:

```bash
ddn connector setenv --connector connector.yaml -- python3 functions.py serve
```

:::warning Python version

The `hasura/python` connector requires [Python](https://www.python.org/downloads/) version `>=3.11`. Please make sure
you have the correct version installed.

:::

### Step 4. Write business logic

The template code that ships with the Python Lambda connector provides some simple examples to help explain how it
works. We can replace those example functions for now.

In this simple example, we're going to transform a timestamp with timezone (eg: "2024-03-14T08:00:00Z") into a nicely
formatted version for humans, eg: "8am, Thursday, March 14th, 2024."

We'll replace the all the default functions in our `functions.py` file with the following:

```python
from hasura_ndc import start
from hasura_ndc.function_connector import FunctionConnector
from datetime import datetime # Don't forget to import datetime at the top of the file!

connector = FunctionConnector()

@connector.register_query
async def format_timezone_data(date_string: str) -> str:
    date = datetime.fromisoformat(date_string)

    day = date.day
    nth = lambda d: "th" if 11 <= d <= 13 else {1: "st", 2: "nd", 3: "rd"}.get(d % 10, "th")

    hours = date.hour
    ampm = "pm" if hours >= 12 else "am"
    hour = hours % 12 or 12

    day_of_week = date.strftime("%A")
    month = date.strftime("%B")
    year = date.year

    return f"{hour}{ampm}, {day_of_week}, {month} {day}{nth(day)}, {year}."


if __name__ == "__main__":
    start(connector)
```

As this is a Python project, you can install any dependency!

### Step 5. Track the new function

To add our function, similar to how we added our individual tables earlier, we can use the following to generate the
related Hasura metadata:

```bash
ddn connector-link update my_python
```

### Step 6. Create a new API build and test

Next, let's create a new build of our supergraph:

```bash
ddn supergraph build local
```

:::tip Start your engines!

Want to test your supergraph? Don't forget to start your GraphQL engine using the following command:

```bash title="Run:"
HASURA_DDN_PAT=$(ddn auth print-pat) docker compose --env-file .env up --build --watch
```

This starts our Hasura Engine and observability tools. `HASURA_DDN_PAT=$(ddn auth print-pat)` gives the Hasura Engine
access to the DDN CLI's authentication token.

:::

You should see your command available, along with its documentation, in the GraphiQL explorer which you should be able
to access at
[`https://console.hasura.io/local/graphql?url=http://localhost:3000`](https://console.hasura.io/local/graphql?url=http://localhost:3000).

If you want a quick way of opening the console, you can run the following command:

```bash title="Run:"
ddn console -l
```

```graphql title=" You can then test your new command with the following query:"
query MyQuery {
  formatTimezoneDate(dateString: "2024-03-14T08:00:00Z")
}
```

<Thumbnail
  src="/img/get-started/beta/console_business_logic_demo_query.png"
  alt="Demo Business Logic query"
  width="1000px"
/>

:::tip Privacy settings in some browsers

Your browser settings or privacy tools may prevent the Console from accessing your local Hasura instance. This could be
due to features designed to protect your privacy and security. Should you encounter one of these issues, we recommend
disabling these settings for the `console.hasura.io` domain.

[Chrome](https://www.google.com/chrome/) and [Firefox](https://www.mozilla.org/en-US/firefox/new/) are the recommended
browsers for the best experience with the Hasura Console including for local development.

:::

:::note Running Python in Docker

As you can see, we're running Python and your functions directly on your own machine. You can also run your functions in
a Docker container along with your other Hasura services. The `connector init` command created a `Dockerfile` and a
`compose.yaml` file for you, so all you would need to do would be to:

- Make sure your port in your connector's `.env` and the one referenced in the
  `my_subgraph/connector/my_python/compose.yaml` file `ports:published` field match and don't conflict with any other
  services you may need to run.
- Add the Python Lambda connector compose file to the main compose file in the root of the project if you want them to
  start all together. Eg:

```yaml title="At the top of the root compose.yaml"
include:
  - path: my_subgraph/connector/my_python/compose.yaml
```

:::

## What did this do?

The commands above initialized a new Python Lambda connector, installed dependencies, and created a new function to
format a timestamp with timezone into a human-readable format. We then added this function to our metadata as a command,
and created a new build of our supergraph.

## Next Steps

You can also [create relationships](/getting-started/build/07-create-a-relationship.mdx) between types in your
supergraph and your commands. This enables you to pair custom business logic with — for example — database tables, and
then transform or enrich data before sending it back to your consumers.

You can learn more about creating these and other relationships on the
[next page](/getting-started/build/07-create-a-relationship.mdx), or you can learn about
[mutating data](/getting-started/build/08-mutate-data.mdx) with examples using the TypeScript connector. Although the
examples for mutating data are provided in Typescript, you could just as easily use the Python connector.
