---
sidebar_position: 7
sidebar_label: Add custom business logic
description: "Learn how to get started with Hasura DDN and your GraphQL API."
keywords:
  - hasura ddn
  - graphql api
  - quickstart
  - getting started
  - guide
---

import Thumbnail from "@site/src/components/Thumbnail";

# Add Custom Business Logic

## What's about to happen?

As we alluded to in the beginning of this guide, the remaining work on top of your existing data source modeling is
authoring and maintaining custom code, or business logic. With Hasura, you can integrate — and even host — this business
logic directly with Hasura DDN and your API.

Hasura handles business logic using the Node.js Lambda data connector. This enables you to author you own custom code,
written in TypeScript, and host it alongside your API. Using this connector, you can transform or enrich data before it
reaches your consumers, or perform any other app business logic you may need.

You can then integrate this custom code as individual [**commands**](/supergraph-modeling/commands.mdx) in your
metadata. This process enables you to simplify client applications and speed up your backend development.

In this guide we will:

- Initialize the `hasura/nodejs` data connector
- Work with Node.js and npm to create a simple script
- Add a new `DataConnectorLink`
- Update the `DataConnectorLink` to track the function script as a command in our metadata
- Create a new API build and test it

## Steps

:::tip Required

- [The DDN CLI, VS Code extension, and Docker installed](/getting-started/00-prerequisites.mdx)
- A new or existing [project](/getting-started/deployment/01-create-a-project.mdx)
- At least one [subgraph](/getting-started/02-init-subgraph.mdx)

:::

### Step 1. Initialize the Node.js Lambda connector

Let's begin by initializing the connector on our project. In the example below, you'll see some familiar flags with new
values being passed to them. We'll call this the `ts_connector` and use the `hasura/nodejs` connector from the connector
hub:

```bash title="From the root of your project, run:"
ddn connector init my_ts \
  --subgraph my_subgraph \
  --hub-connector hasura/nodejs \
  --configure-port 8083 \
  --add-to-compose-file docker-compose.hasura.yaml
```

In this command, we're passing a few important values.

**Connector name**

We're naming the connector `my_ts` in this example, but you can call it whatever makes sense to you.

**Connector: --hub-connector**

We're specifying that this connector should be the: `hasura/nodejs`, connector listed in the
[Connector Hub](https://hasura.io/connectors/nodejs-lambda).

**Port: `configure-port`**

We're specifying the port to run the connector on. This is important to avoid port collisions with other connectors or
services which you might have running on your machine. Remember to use a different port for each connector you may have
running.

**Compose file: `--add-to-compose-file`**

We're specifying the `--add-to-compose-file` flag to add the connector's **own** Docker compose file to the main
`docker-compose.hasura.yaml` file. This is for convenience and allows us to start the Hasura Engine and connectors
together.

:::tip Best practices

Importantly, a data connector can only connect to one data source.

The project will be kept organized with each data connector's configuration located in a relevant subgraph directory. In
this example the CLI will create a `my_subgraph/connector/my_ts` directory if it doesn't exist. You can also change
this directory by passing a `--dir` flag to the CLI.

The name of the connector and the directory in which the configuration is stored, `my_ts` in this example, should
match for convenience and clarity sake.

In subsequent steps, when running your connector locally, it's critical to ensure the port value matches the connection
string you provide in your subgraph's `.env.my_subgraph` file.

:::


### What did this do?

This command created the following file structure in a `my_subgraph/connector/my_ts` directory, with the `functions.ts`
file being your connector's entrypoint:

```bash
.
├── .ddnignore
├── .env.local
├── .hasura-connector
├── connector.yaml
├── docker-compose.my_ts.yaml
# highlight-start
├── functions.ts
# highlight-end
├── package-lock.json
├── package.json
└── tsconfig.json
```

### Step 2. Add the DataConnectorLink

As with any other connector, we'll now need to create the `DataConnectorLink` which will translate our TypeScript
functions into commands that can be exposed as queries and mutations via our GraphQL API. Create this using:

```bash title="From the root of your project, run:"
ddn connector-link add my_ts --subgraph my_subgraph
```

Then, update the values in your subgraph's `.env.my_subgraph` file to include this connector.

```env
MY_SUBGRAPH_MY_TS_READ_URL=http://local.hasura.dev:8083
MY_SUBGRAPH_MY_TS_WRITE_URL=http://local.hasura.dev:8083
```

These values are already referenced in `my_subgraph/metadata/my_ts/my_ts.hml`.

### Step 3. Install npm package dependencies

Within our `my_ts` connector directory, let's install any necessary dependencies:

```bash
cd my_subgraph/connector/my_ts && npm i
```

Then, from the `my_ts` directory run this command to use the included `dotenv` package to load environment variables
from the `. env.local` file, start the connector, and watch for any changes:

```bash
npx dotenv -e .env.local -- npm run watch
```

:::info Node.js version

The `hasura/nodejs` connector uses Node.js version `>=20`. Please make sure you have the correct version installed.

:::

### Step 4. Write business logic

In this simple example, we're going to transform a timestamp with timezone (eg: "2024-03-14T08:00:00Z") into a nicely
formatted version for humans, eg: "8am, Thursday, March 14th, 2024."

We'll replace the default `hello()` function in our `functions.ts` file with the following:

```ts
/**
 * @readonly
 */
export async function formatTimezoneDate(dateString: string): Promise<string> {
  const date = new Date(dateString);

  const day = date.getDate();
  const nth = (d: number) => {
    if (d > 3 && d < 21) return "th";
    switch (d % 10) {
      case 1:
        return "st";
      case 2:
        return "nd";
      case 3:
        return "rd";
      default:
        return "th";
    }
  };

  const hours = date.getHours();
  const ampm = hours >= 12 ? "pm" : "am";
  const hour = hours % 12 || 12;

  const dayOfWeek = date.toLocaleString("en-US", { weekday: "long" });
  const month = date.toLocaleString("en-US", { month: "long" });
  const year = date.getFullYear();

  return `${hour}${ampm}, ${dayOfWeek}, ${month} ${day}${nth(day)}, ${year}.`;
}
```

As this is a Node.js project, you can install any dependency!

### Step 5. Track the new function

To add our function, similar to how we added our individual tables earlier, we can use the following to generate the
related Hasura metadata:

```bash
ddn connector-link update my_ts --subgraph my_subgraph --add-all-resources
```

### Step 6. Create a new API build and test

Next, let's create a new build of our supergraph:

```bash
ddn supergraph build local --output-dir ./engine
```

:::tip Start your engines!

Want to test your supergraph? Don't forget to start your GraphQL engine and connectors using the following command.

```bash title="From the root of your project, run:"
HASURA_DDN_PAT=$(ddn auth print-pat) docker compose -f docker-compose.hasura.yaml watch
```

This starts our Hasura Engine, observability tools and the Node.js connector since we added the connector's Docker
compose file to the main `docker-compose.hasura.yaml` file using the `--add-to-compose-file` flag when we
initialized the connector. `HASURA_DDN_PAT=$(ddn auth print-pat)` gives the Hasura Engine access to the DDN CLI's
authentication token.

:::

You should see your command available, along with its documentation, in the GraphiQL explorer which you should be able
to access at `https://console.hasura.io/local/graphql?url=http://localhost:3000`. You can then test your new command
with a string such as: `"2024-03-14T08:00:00Z"`.

<Thumbnail
  src="/img/get-started/beta/console_business_logic_demo_query.png"
  alt="Demo Business Logic query"
  width="1000px"
/>

## What did this do?

The commands above initialized a new Node.js Lambda connector, installed dependencies, and created a new function to
format a timestamp with timezone into a human-readable format. We then added this function to our metadata as a
command, and created a new build of our supergraph.

## Next Steps

You can also create relationships between types in your supergraph and your commands. This enables you to pair custom
business logic with — for example — database tables, and then transform or enrich data before sending it back to your
consumers.

You can learn more about creating these and other relationships on the
[next page](/getting-started/08-create-a-relationship.mdx), or you can learn about
[mutating data](/getting-started/09-mutate-data.mdx) using the TypeScript connector.
