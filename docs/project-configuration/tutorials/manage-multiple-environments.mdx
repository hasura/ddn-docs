---
sidebar_position: 2
sidebar_label: Manage mulitple environments
description: ""
keywords:
  - hasura
  - hasura ddn
---

# Manage Multiple Environments

## Introduction

Managing multiple contexts in Hasura DDN allows you to replicate the functionality of traditional environments like
`staging` and `production`, but with greater flexibility. Instead of rigidly-defined environments, Hasura DDN uses
contexts to store key details such as project configurations, metadata, and environment variables. This approach lets
you switch between different setups without disrupting your workflow or end users.

In this tutorial, you'll learn how to:

- Set up multiple contexts to test and collaborate on your project
- Use the CLI to manage your project's contexts
- Build and deploy projects with shared metadata across different contexts

This tutorial should take less than twenty minutes.

## Setup

### Step 1. Initialize a new local project

```sh title="Create a new local project:"
ddn supergraph init environments-example && cd environments-example
```

This will scaffold out the necessary files for a Hasura DDN project in a new `environments-example` directory.

### Step 2. Add a data source and seed data

In this tutorial, we'll use the PostgreSQL connector and some seed data.

```sh title="In your project directory, run:"
ddn connector init my_pg -i
```

From the dropdown, start typing `PostgreSQL` and hit enter to advance through all the options.

The CLI will output something similar to this:

```plaintext
HINT To access the local Postgres database:
- Run: docker compose -f app/connector/my_pg/compose.postgres-adminer.yaml up -d
- Open Adminer in your browser at http://localhost:5143 and create tables
- To connect to the database using other clients use postgresql://user:password@local.hasura.dev:8105/dev
```

```sh title="Use the hint from the CLI output:"
docker compose -f app/connector/my_pg/compose.postgres-adminer.yaml up -d
```

Run `docker ps` to see on which port Adminer is running. Then, you can then navigate to the address below to access it:

```plaintext
http://localhost:<ADMINER_PORT>
```

```sql title="Next, via Adminer select SQL command from the left-hand nav, then enter the following:"
--- Create the table
CREATE TABLE users (
  id SERIAL PRIMARY KEY,
  name TEXT NOT NULL,
  age INT NOT NULL
);

--- Insert some data
INSERT INTO users (name, age) VALUES ('Alice', 25);
INSERT INTO users (name, age) VALUES ('Bob', 30);
INSERT INTO users (name, age) VALUES ('Charlie', 35);
```

You can verify this worked by using Adminer to query all records from the `users` table:

```sql
SELECT * FROM users;
```

### Step 3. Generate the Hasura metadata

```sh title="Next, use the CLI to introspect your PostgreSQL database:"
ddn connector introspect my_pg
```

After running this, you should see a representation of your database's schema in the
`app/connector/my_pg/configuration.json` file; you can view this using `cat` or open the file in your editor.

```sh title="Now, track the table from your PostgreSQL database as a model in your DDN metadata:"
ddn models add my_pg users
```

Open the `app/metadata` directory and you'll find a newly-generated file: `Users.hml`. The DDN CLI will use this Hasura
Metadata Language file to represent the `users` table from PostgreSQL in your API as a
[model](/supergraph-modeling/models.mdx).

### Step 4. Create a new local build and test the API

```sh title="To create a local build, run:"
ddn supergraph build local
```

The build is stored as a set of JSON files in `engine/build`.

```sh title="Start your local Hasura DDN Engine and PostgreSQL connector:"
ddn run docker-start
```

Your terminal will be taken over by logs for the different services.

```sh title="In a new terminal tab, open your local console:"
ddn console --local
```

```graphql title="In the GraphiQL explorer of the console, write this query:"
query {
  users {
    id
    name
    age
  }
}
```

```json title="You'll get the following response:"
{
  "data": {
    "users": [
      {
        "id": 1,
        "name": "Alice",
        "age": 25
      },
      {
        "id": 2,
        "name": "Bob",
        "age": 30
      },
      {
        "id": 3,
        "name": "Charlie",
        "age": 35
      }
    ]
  }
}
```

## Create a new context

### Step 5. Create a new project context and switch to it

```sh title="From the project directory, run:"
ddn context create-context staging
```

Verify this by opening the `.hasura/context.yaml` file. You'll see a `contexts` array with two entries: `default` and
your newly-created `staging`.

:::tip What can be stored in context?

Contexts store a series of key-value pairs that make it easy to switch between different setups. Valid keys are:

- `project` — identifying the cloud project's name to be used for commands which require a `--project` flag.
- `supergraph` — identifying the `supergraph.yaml` configuration file to be used for commands which require a
  `--supergraph` flag.
- `subgraph` — identifying the current subgraph to be used for commands which require a `--subgraph` flag.
- `localEnvFile` — identifying the file of local environment variables to be used during development.
- `cloudEnvFile` — identifying the file of cloud environment variables to be used during cloud builds.
- `selfHostedDataPlane` — the ID of the self-hosted data plane if you're using a Private DDN.

:::

### Step 6. Update the context values

```sh title="First, set the supergraph configuration:"
ddn context set supergraph "supergraph.yaml"
```

```sh title="Then, which subgraphs to include:"
ddn context set subgraph "app/subgraph.yaml"
```

```sh title="Finally, stub out a local .env.staging file and add it to your staging context:"
touch .env.staging && ddn context set localEnvFile ".env.staging"
```

You'll see each of these key-value pairs added to your `staging` context.

:::tip Customize these values

The examples provided here are starting points and can be adapted to suit your project's requirements. Ideally, the
values included in your `.env.staging` file will reference resources such as testing database instances. Keep the keys
consistent with those in your production `.env` files, but assign different values tailored for staging or testing
environments.

:::

### Step 7. Create a new staging cloud project

```sh title="Using your new context, create a cloud project:"
ddn project init --env-file-name ".env.staging.cloud"
```

The CLI will add the project's name and your `cloudEnvFile` to your `staging` context.

### Step 8. Create a new build on your staging project

```sh
ddn supergraph build create
```

The CLI will output information about the build, including a console URL which you can open in your browser. Your local
metadata was used to create this API build on your `staging` project.

### Step 9. Create a new production cloud project

```sh title="First, switch contexts:"
ddn context set-current-context default
```

```sh title="Then, create a new project:"
ddn project init
```

In your `context.yaml`, you'll now see a `project` and `cloudEnvFile` value for your `default` context. We're
considering this our `production` instance.

### Step 10. Create a new build on your production project

```sh title="Since our current context is default, we can now use the same metadata to create a productioun build:"
ddn supergraph build create
```

Just as with our `staging` project, you can navigate to the console URL output by the CLI and explore your `production`
build, which should be identical to your `staging` build.

## Next steps

Now that you know how contexts can help you manage environments, see how easy it is to
[set up CI/CD](/deployment/ddn/deploy-your-supergraph#cicd) using the CLI and contexts.
