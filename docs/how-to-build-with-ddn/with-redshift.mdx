---
sidebar_position: 7
sidebar_label: With Redshift
description: "Learn the basics of Hasura DDN and how to get started with a Redshift database."
keywords:
  - hasura ddn
  - graphql api
  - getting started
  - guide
  - redshift
---

import Prereqs from "@site/docs/_prereqs.mdx";

# Get Started with Hasura DDN and Amazon Redshift

## Overview

This tutorial will guide you through setting up a Hasura DDN project with Amazon Redshift. You'll learn how to:

- Set up a new Hasura DDN project
- Connect it to a Redshift database
- Generate Hasura metadata
- Create a build
- Run your first query
- Create relationships
- Mutate data

Additionally, we'll familiarize you with the steps and workflows necessary to iterate on your API.

You'll also need:

- An AWS account
- A Redshift database with namespace
- An IAM user with access to the Redshift database
- The IAM user's credentials

<Prereqs />

## Tutorial

### Step 1. Authenticate your CLI

```sh title="Before you can create a new Hasura DDN project, you need to authenticate your CLI:"
ddn auth login
```

This will launch a browser window prompting you to log in or sign up for Hasura DDN. After you log in, the CLI will
acknowledge your login, giving you access to Hasura Cloud resources.

### Step 2. Scaffold out a new local project

```sh title="Next, create a new local project:"
ddn supergraph init my-project && cd my-project
```

Once you move into this directory, you'll see your project scaffolded out for you. You can view the structure by either
running `ls` in your terminal, or by opening the directory in your preferred editor.

### Step 3. Create a new Redshift database

In the AWS console, navigate to the [Redshift page](https://console.aws.amazon.com/redshift) and create a new database
called `hasura_demo` in your namespace. You can do so by clicking "Query data" in the top right. Then click the "+
Create" button and select database. Select the appropriate cluster / workgroup, name the database `hasura_demo` and
click "Create database".

### Step 4. Seed your Redshift database

Create a table with name `users` by using the query editor in the Redshift console. Make sure to select the
`hasura_demo` database from the dropdown above the query editor.

```SQL title="Create a table:"
CREATE TABLE public.users (
  id INT PRIMARY KEY,
  name TEXT NOT NULL,
  age INT NOT NULL
);
```

```SQL title="Then, seed the table:"
INSERT INTO public.users (id, name, age) VALUES (1, 'Alice', 25), (2, 'Bob', 30), (3, 'Charlie', 35);
```

### Step 5. Configure your Redshift connector

1. Move your downloaded service account key file to your connector folder:

```sh title="Copy your service account key file to the connector directory:"
mv /path/to/your/key.json app/connector/my_redshift/key.json
```

2. Configure your JDBC connection string in the connector's environment variable `.env` file. The connection string
   should follow this format:

```plaintext
APP_MY_REDSHIFT_JDBC_URL=jdbc:redshift://localhost:5439/hasura_demo;DatabaseName=hasura_demo;OAuthType=0;OAuthServiceAcctEmail=your-service-account-email;OAuthPvtKey=/etc/connector/your-key.json
```

In the connection string make sure to replace:

- `your-database-name` with your Redshift database name
- `your-service-account-email` with your IAM user's email
- `your-key.json` must match the name of the file you placed in the connector folder

### Step 6. Initialize your Redshift connector

```sh title="In your project directory, run:"
ddn connector init my_redshift -i
```

From the dropdown, select `/hasura/redshift` (you can type to filter the list), then hit enter to accept the default of
all the options.

The CLI will output something similar to this:

```plaintext
HINT To access the local Redshift database:
- Run: docker compose -f app/connector/my_redshift/compose.redshift-adminer.yaml up -d
- Open Adminer in your browser at http://localhost:5143 and create tables
- To connect to the database using other clients use redshift://user:password@local.hasura.dev:8105/dev
```

### Step 4. Start the local Redshift container and Adminer

```sh title="Use the hint from the CLI output:"
docker compose -f app/connector/my_redshift/compose.redshift-adminer.yaml up -d
```

Run `docker ps` to see on which port Adminer is running. Then, you can then navigate to the address below to access it:

```plaintext
http://localhost:<ADMINER_PORT>
```

### Step 5. Create a table in your Redshift database

```sql title="Next, via Adminer select SQL command from the left-hand nav, then enter the following:"
--- Create the table
CREATE TABLE users (
  id SERIAL PRIMARY KEY,
  name TEXT NOT NULL,
  age INT NOT NULL
);

--- Insert some data
INSERT INTO users (name, age) VALUES ('Alice', 25);
INSERT INTO users (name, age) VALUES ('Bob', 30);
INSERT INTO users (name, age) VALUES ('Charlie', 35);
```

You can verify this worked by using Adminer to query all records from the `users` table:

```sql
SELECT * FROM users;
```

### Step 6. Introspect your Redshift database

```sh title="Next, use the CLI to introspect your Redshift database:"
ddn connector introspect my_redshift
```

After running this, you should see a representation of your database's schema in the
`app/connector/my_redshift/configuration.json` file; you can view this using `cat` or open the file in your editor.

```sh title="Additionally, you can check which resources are available â€” and their status â€” at any point using the CLI:"
ddn connector show-resources my_redshift
```

### Step 7. Add your model

```sh title="Now, track the table from your Redshift database as a model in your DDN metadata:"
ddn models add my_redshift users
```

Open the `app/metadata` directory and you'll find a newly-generated file: `Users.hml`. The DDN CLI will use this Hasura
Metadata Language file to represent the `users` table from Redshift in your API as a
[model](/reference/metadata-reference/models.mdx).

### Step 8. Create a new build

```sh title="To create a local build, run:"
ddn supergraph build local
```

The build is stored as a set of JSON files in `engine/build`.

### Step 9. Start your local services

```sh title="Start your local Hasura DDN Engine and Redshift connector:"
ddn run docker-start
```

Your terminal will be taken over by logs for the different services.

### Step 10. Run your first query

```sh title="In a new terminal tab, open your local console:"
ddn console --local
```

```graphql title="In the GraphiQL explorer of the console, write this query:"
query {
  users {
    id
    name
    age
  }
}
```

```json title="You'll get the following response:"
{
  "data": {
    "users": [
      {
        "id": 1,
        "name": "Alice",
        "age": 25
      },
      {
        "id": 2,
        "name": "Bob",
        "age": 30
      },
      {
        "id": 3,
        "name": "Charlie",
        "age": 35
      }
    ]
  }
}
```

### Step 11. Iterate on your Redshift schema

```sql title="Via Adminer, add a new table and insert some data to your Redshift database:"
-- Create the posts table
CREATE TABLE posts (
  id SERIAL PRIMARY KEY,
  user_id INT NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  title TEXT NOT NULL,
  content TEXT NOT NULL,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Insert some seed data
INSERT INTO posts (user_id, title, content) VALUES
  (1, 'My First Post', 'This is Alice''s first post.'),
  (1, 'Another Post', 'Alice writes again!'),
  (2, 'Bob''s Post', 'Bob shares his thoughts.'),
  (3, 'Hello World', 'Charlie joins the conversation.');
```

```sql title="Using Adminer, verify this by running the following query:"
-- Fetch all posts with user information
SELECT
  posts.id AS post_id,
  posts.title,
  posts.content,
  posts.created_at,
  users.name AS author
FROM
  posts
JOIN
  users ON posts.user_id = users.id;
```

You should see a list of posts returned with the author's information joined from the `users` table

### Step 12. Refresh your metadata and rebuild your project

:::tip

The following steps are necessary each time you make changes to your **source** schema. This includes, adding,
modifying, or dropping tables.

:::

#### Step 12.1. Re-introspect your data source

```sh title="Run the introspection command again:"
ddn connector introspect my_redshift
```

In `app/connector/my_redshift/configuration.json`, you'll see schema updated to include operations for the `posts`
table. In `app/metadata/my_redshift.hml`, you'll see `posts` present in the metadata as well.

#### Step 12.2. Update your metadata

```sh title="Add the posts model:"
ddn model add my_redshift "posts"
```

#### Step 12.3. Create a new build

```sh title="Next, create a new build:"
ddn supergraph build local
```

#### Step 12.4. Restart your services

```sh title="Bring down the services by pressing CTRL+C and start them back up:"
ddn run docker-start
```

### Step 13. Query your new build

```graphql title="Head back to your console and query the posts model:"
query GetPosts {
  posts {
    id
    title
    content
  }
}
```

```json title="You'll get a response like this:"
{
  "data": {
    "posts": [
      {
        "id": 1,
        "title": "My First Post",
        "content": "This is Alice's first post."
      },
      {
        "id": 2,
        "title": "Another Post",
        "content": "Alice writes again!"
      },
      {
        "id": 3,
        "title": "Bob's Post",
        "content": "Bob shares his thoughts."
      },
      {
        "id": 4,
        "title": "Hello World",
        "content": "Charlie joins the conversation."
      }
    ]
  }
}
```

### Step 14. Create a relationship

```sh title="Since there's already a foreign key on the posts table in Redshift, we can easily add the relationship:"
ddn relationship add my_redshift "posts"
```

You'll see a new metadata object added to the `app/metadata/posts.hml` file of kind `Relationship` explaining the
relationship between `posts` and `users`.

### Step 15. Rebuild your project

```sh title="As your metadata has changed, create a new build:"
ddn supergraph build local
```

```sh title="Bring down the services by pressing CTRL+C and start them back up:"
ddn run docker-start
```

### Step 16. Query using your relationship

```graphql title="Now, execute a nested query using your relationship:"
query GetPosts {
  posts {
    id
    title
    content
    user {
      id
      name
      age
    }
  }
}
```

```json title="Which should return a result like this:"
{
  "data": {
    "posts": [
      {
        "id": 1,
        "title": "My First Post",
        "content": "This is Alice's first post.",
        "user": {
          "id": 1,
          "name": "Alice",
          "age": 25
        }
      },
      {
        "id": 2,
        "title": "Another Post",
        "content": "Alice writes again!",
        "user": {
          "id": 1,
          "name": "Alice",
          "age": 25
        }
      },
      {
        "id": 3,
        "title": "Bob's Post",
        "content": "Bob shares his thoughts.",
        "user": {
          "id": 2,
          "name": "Bob",
          "age": 30
        }
      },
      {
        "id": 4,
        "title": "Hello World",
        "content": "Charlie joins the conversation.",
        "user": {
          "id": 3,
          "name": "Charlie",
          "age": 35
        }
      }
    ]
  }
}
```

### Step 17. Add all commands

We'll track the available operations â€” for inserting, updating, and deleting â€” on our `users` and `posts` tables as
commands.

```sh title="Add all available commands:"
ddn command add my_redshift "*"
```

You'll see newly-generated metadata files in the `metadata` directory for your connector that represent insert, update,
and delete operations.

```sh title="As your metadata has changed, create a new build:"
ddn supergraph build local
```

```sh title="Bring down the services by pressing CTRL+C and start them back up:"
ddn run docker-start
```

### Step 18. Insert new data

```graphql title="Create a new post for Charlie:"
mutation InsertSinglePost {
  insertPosts(
    objects: {
      content: "I am an expert in Bird Law and I demand satisfaction."
      title: "Charlie has more to say"
      userId: "3"
    }
  ) {
    returning {
      id
      title
      content
      user {
        id
        name
      }
    }
  }
}
```

You should see a response that returns your inserted data along with the `id` and `name` fields for the author.

## Next steps

Congratulations on completing your first Hasura DDN project with Redshift! ðŸŽ‰

Here's what you just accomplished:

- You started with a fresh project and connected it to a local Redshift database.
- You set up metadata to represent your tables and relationships, which acts as the blueprint for your API.
- Then, you created a build â€” essentially compiling everything into a ready-to-use API â€” and successfully ran your first
  GraphQL queries to fetch data.
- Along the way, you learned how to iterate on your schema and refresh your metadata to reflect changes.
- Finally, we looked at how to enable mutations and insert data using your new API.

Now, you're equipped to connect and expose your data, empowering you to iterate and scale with confidence. Great work!

Take a look at our Redshift docs to learn more about how to use Hasura DDN with Redshift. Or, if you're ready, get
started with adding [permissions](/auth/permissions/index.mdx) to control access to your API.
