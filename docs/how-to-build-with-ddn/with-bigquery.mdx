---
sidebar_position: 7
sidebar_label: With BigQuery
description: "Learn how to connect and use Google BigQuery with Hasura DDN to create a real-time GraphQL API."
keywords:
  - hasura ddn
  - graphql api
  - getting started
  - guide
  - bigquery
  - google bigquery
---

import Prereqs from "@site/docs/_prereqs.mdx";

# Get Started with Hasura DDN and BigQuery

## Overview

This tutorial will guide you through setting up a Hasura DDN project with Google BigQuery. You'll learn how to:

- Set up a new Hasura DDN project
- Connect it to a BigQuery database
- Configure authentication
- Generate Hasura metadata
- Create a build
- Run your first query

Additionally, we'll familiarize you with the steps and workflows necessary to iterate on your API.

This tutorial assumes you have:

- A Google Cloud account
- A service account with appropriate permissions for the project and BigQuery dataset you'll use.
- The service account key file downloaded from Google Cloud Console

<Prereqs />

## Tutorial

### Step 1. Authenticate your CLI

```sh title="Before you can create a new Hasura DDN project, you need to authenticate your CLI:"
ddn auth login
```

This will launch a browser window prompting you to log in or sign up for Hasura DDN. After you log in, the CLI will
acknowledge your login, giving you access to Hasura Cloud resources.

### Step 2. Scaffold out a new local project

```sh title="Next, create a new local project:"
ddn supergraph init my-project && cd my-project
```

Once you move into this directory, you'll see your project scaffolded out for you. You can view the structure by either
running `ls` in your terminal, or by opening the directory in your preferred editor.

### Step 3. Create a new BigQuery dataset

In the Google Cloud console, navigate to the [BigQuery page](https://console.cloud.google.com/bigquery) and create a new
dataset called `hasura_demo`. You can do so by clicking "Studio" in the left sidebar, then with the three dots button
next to the project name in the "Explorer", selecting "Create data set". Give it an id and click "Create data set".

Make sure that in "IAM and admin", in "Service accounts", you have a service account with at least the "BigQuery User"
role.

You can also create and download a JSON key file for the service account by clicking on its name and selecting "Keys" in
the navigation menu.

The JSON key file should look like this example:

```json
{
  "type": "service_account",
  "project_id": "project-id",
  "private_key_id": "private-key-id",
  "private_key": "-----BEGIN PRIVATE KEY-----\nprivate-key\n-----END PRIVATE KEY-----\n",
  "client_email": "service-account-email",
  "client_id": "client-id",
  "auth_uri": "https://accounts.google.com/o/oauth2/auth",
  "token_uri": "https://oauth2.googleapis.com/token",
  "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
  "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/service-account-email"
}
```

### Step 4. Seed your BigQuery database

Create a table in your data set with name `users` by clicking on the `hasura_demo` dataset in the BigQuery console and
then clicking on the `+ Create table` button in the top right. Select `Empty table` and give it a name.

You can use the following schema text definition to create the table in the BigQuery console:

```json
[
  {
    "name": "user_id",
    "type": "INTEGER",
    "mode": "REQUIRED"
  },
  {
    "name": "name",
    "type": "STRING",
    "mode": "NULLABLE"
  },
  {
    "name": "age",
    "type": "INTEGER",
    "mode": "NULLABLE"
  }
]
```

Once created, you can click on the table and the "Query" button to seed the table with some data:

```SQL title="Then, seed the table:"
INSERT INTO hasura_demo.users (user_id, name, age) VALUES (1, 'Alice', 25), (2, 'Bob', 30), (3, 'Charlie', 35);
```

### Step 4. Initialize your BigQuery connector

```sh title="In your project directory, run:"
ddn connector init my_bigquery -i
```

From the dropdown, select `/hasura/bigquery-jdbc` (you can type to filter the list), then hit enter to accept the
default of all the options including the JDBC connection string which we will edit in the ext.

### Step 4. Configure BigQuery Authentication

1. Place your service account key file renamed exactly `key.json` in the connector folder:

```sh title="Copy your service account key file to the connector directory:"
cp /path/to/your/key.json app/connector/my_bigquery/key.json
```

2. Configure your JDBC connection string in the connector's environment variable `.env` file. The connection string
   should follow this format:

```plaintext
APP_MYBIGQUERY_JDBC_JDBC_URL=jdbc:bigquery://https://www.googleapis.com/bigquery/v2:443;ProjectId=your-project-id;DefaultDataset=your-dataset;OAuthType=0;OAuthServiceAcctEmail=your-service-account-email;OAuthPvtKey=/etc/connector/key.json
```

In the connection string make sure to replace:

- `your-project-id` with your Google Cloud project ID
- `your-dataset` with your default BigQuery dataset
- `your-service-account-email` with your service account email

### Step 5. Introspect your BigQuery database

```sh title="Use the CLI to introspect your BigQuery database:"
ddn connector introspect my_bigquery
```

After running this, you should see a representation of your database's schema in the
`app/connector/my_bigquery/configuration.json` file.

```sh title="You can check which resources are available — and their status — at any point using the CLI:"
ddn connector show-resources my_bigquery
```

### Step 6. Add your models

```sh title="Track your BigQuery tables as models in your DDN metadata:"
ddn models add my_bigquery your_table_name
```

Open the `app/metadata` directory and you'll find newly-generated files for each table you track. The DDN CLI uses these
Hasura Metadata Language files to represent your BigQuery tables in your API as
[models](/reference/metadata-reference/models.mdx).

### Step 7. Create a new build

```sh title="To create a local build, run:"
ddn supergraph build local
```

The build is stored as a set of JSON files in `engine/build`.

### Step 8. Start your local services

```sh title="Start your local Hasura DDN Engine and BigQuery connector:"
ddn run docker-start
```

Your terminal will be taken over by logs for the different services.

### Step 9. Run your first query

```sh title="In a new terminal tab, open your local console:"
ddn console --local
```

```graphql title="In the GraphiQL explorer of the console, write a query for your table:"
query GetUsers {
  users {
    userId
    name
    age
  }
}
```

```json title="You'll get a response like this:"
{
  "data": {
    "users": [
      {
        "userId": "1",
        "name": "Alice",
        "age": "25"
      },
      {
        "userId": "3",
        "name": "Charlie",
        "age": "35"
      },
      {
        "userId": "2",
        "name": "Bob",
        "age": "30"
      }
    ]
  }
}
```

### Step 10. Iterate on your API

Add a new table to your BigQuery dataset with the name `posts`. You can use the following schema text definition to
create the table in the console:

```json title="Add a new posts table to your BigQuery dataset:"
[
  {
    "name": "user_id",
    "type": "INTEGER",
    "mode": "REQUIRED"
  },
  {
    "name": "post_id",
    "type": "INTEGER",
    "mode": "REQUIRED"
  },
  {
    "name": "title",
    "type": "STRING",
    "mode": "NULLABLE",
    "maxLength": "255"
  },
  {
    "name": "content",
    "type": "STRING",
    "mode": "NULLABLE"
  }
]
```

Once created, you can click on the table and the "Query" button to seed the table with some data:

```SQL title="Seed the new table:"
INSERT INTO hasura_demo.posts (user_id, post_id, title, content) VALUES
  (1, 1, 'My First Post', 'This is the first post for Alice.'),
  (1, 2, 'Another Post', 'Alice writes again!'),
  (2, 3, 'Bobs Post', 'Bob shares his thoughts.'),
  (3, 4, 'Hello World', 'Charlie joins the conversation.');
```

#### Step 11.1. Re-introspect your data source

```sh title="Run the introspection command again:"
ddn connector introspect my_bigquery
```

In `app/connector/my_bigquery/configuration.json`, you'll see schema updated to include operations for the `posts`
table. In `app/metadata/my_bigquery.hml`, you'll see `posts` present in the metadata as well.

#### Step 11.2. Update your metadata

```sh title="Add the posts model:"
ddn models add my_bigquery posts
```

### Step 11. Create a Relationship in your Hasura metadata

Let's also create a Relationship in our Hasura metdata for between the `users` and `posts` tables.

Manually add the following to the bottom of your `app/metadata/Posts.hml` file:

```yaml title="Add a new relationship to your Hasura metadata:"
---
kind: Relationship
version: v1
definition:
  name: user
  sourceType: Posts
  target:
    model:
      name: Users
      relationshipType: Object
  mapping:
    - source:
        fieldPath:
          - fieldName: userId
      target:
        modelField:
          - fieldName: userId
```

### Step 14. Rebuild your project

Bring down the services by pressing `CTRL+C` in the terminal tab logging their activity.

```sh title="As your metadata has changed, create a new build:"
ddn supergraph build local
```

```sh title="Bring everything back up:"
ddn run docker-start
```

### Step 12. Run your first query with a relationship

```graphql title="Run your first query with a relationship:"
query GetPostsWithAuthors {
  posts {
    postId
    title
    content
    user {
      age
      name
      userId
    }
  }
}
```

```json title="You'll get a response like this:"
{
  "data": {
    "posts": [
      {
        "postId": "1",
        "title": "My First Post",
        "content": "This is the first post for Alice.",
        "user": {
          "age": "25",
          "name": "Alice",
          "userId": "1"
        }
      },
      {
        "postId": "2",
        "title": "Another Post",
        "content": "Alice writes again!",
        "user": {
          "age": "25",
          "name": "Alice",
          "userId": "1"
        }
      },
      {
        "postId": "3",
        "title": "Bobs Post",
        "content": "Bob shares his thoughts.",
        "user": {
          "age": "30",
          "name": "Bob",
          "userId": "2"
        }
      },
      {
        "postId": "4",
        "title": "Hello World",
        "content": "Charlie joins the conversation.",
        "user": {
          "age": "35",
          "name": "Charlie",
          "userId": "3"
        }
      }
    ]
  }
}
```

## Additional Resources

- [BigQuery Connector in Hasura Hub](https://hasura.io/connectors/bigquery-jdbc)
- [BigQuery JDBC Driver Documentation](https://cloud.google.com/bigquery/docs/reference/odbc-jdbc-drivers#current_jdbc_driver)
- [Hasura V3 Documentation](https://hasura.io/docs/3.0)
