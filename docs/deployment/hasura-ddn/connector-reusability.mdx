---
sidebar_position: 3
description: "Reuse connectors across multiple subgraphs or multiple projects"
keywords:
  - hasura
  - ddn
  - connector
  - data connector
  - native data connector
  - reusable connector
  - deployment
  - reusability
  - private ddn
---

# Connector Reusability

## Introduction

Hasura DDN allows you to reuse the same connector deployment across multiple subgraphs, and even across multiple
projects. This pattern offers several advantages, especially in scenarios where you have multiple teams or applications
needing access to the same underlying data source.

## Benefits of connector reusability

- **Reduced Redundancy:** Avoid deploying the same connector multiple times, saving resources and simplifying
  management.
- **Centralized Configuration:** Manage the connector's configuration (like connection strings, credentials, etc.) in a
  single place. Changes only need to be made once.
- **Simplified Deployment:** Deploy and update the connector independently of the subgraphs that use it.
- **Location Optimization:** You can locate the connector as close to the data source as possible, which can
  significantly improve performance.
- **Decoupled Management:** By having a dedicated repository for connector deployment, you can manage connector updates
  independently of the data domain teams' subgraph development.

## How it works

When you deploy a connector to Hasura DDN, it generates unique read and write URLs that are stored in your `.env.cloud`
file. By sharing these URLs, you can reuse the same connector across multiple subgraphs and even across multiple
projects. This means the connector only needs to be deployed once, and all subgraphs can reference the same deployed
instance.

## Example scenario: Public DDN

Let's say you have a PostgreSQL database hosted in `gcp-us-west2`. You have two teams: a "Products" team and a "Reviews"
team. Both teams need to access data from this database. Instead of deploying two separate PostgreSQL connectors, you
can deploy a single connector in `gcp-us-west2` (close to the database) and reuse it across both subgraphs.

### Step 1. Recommended: Create a dedicated connector repository

First, create a new repository specifically for managing the connector deployment. This repository will be separate from
any data domain team's repositories and supergraphs.

```sh
mkdir postgres-connector
cd postgres-connector
ddn supergraph init .
ddn connector init my_postgres -i
```

After [initializing the connector](/how-to-build-with-ddn/with-postgresql.mdx), you can introspect the database to
understand its structure:

```sh
ddn connector introspect my_postgres
ddn connector show-resources my_postgres
```

Add any resources you need:

```sh
ddn model add my_postgres "*"
ddn command add my_postgres "*"
ddn relationship add my_postgres "*"
```

Determine where the connector should be deployed. If you are using public DDN you will need a project:

```sh
ddn project init
```

This will respond with a project ID and the subgraphs which were created. It will also create a `.env.cloud` file with
some initial values.

In this file, add a `HASURA_SERVICE_TOKEN_SECRET` environment variable with a random value. This will be used to secure
and authenticate the connector when it is built and deployed.

```env
APP_MY_POSTGRES_HASURA_SERVICE_TOKEN_SECRET="fdAwGRXSTVAe-gSdTpRtxw=="
```

Next, build and deploy the connector to Hasura DDN:

```sh
ddn connector build create --connector ./app/connector/my_postgres/connector.yaml --target-env-file ./.env.cloud  --target-subgraph ./app/subgraph.yaml --target-connector-link my_postgres
```

The command will respond with the ID, read and write URLs and authorization header for the deployed connector, for
example:

```text
+--------------------------+------------------------------------------------------------------------------------------------------+
| ConnectorBuild Id        | 240ec317-ac19-4e87-9bcc-2b8f348f9b0a                                                                 |
+--------------------------+------------------------------------------------------------------------------------------------------+
| ConnectorBuild Read URL  | http://c7-bzh3anilpx.gcp.postgres.ndc.internal/deployment/240ec317-ac19-4e87-9bcc-2b8f348f9b0a-read  |
+--------------------------+------------------------------------------------------------------------------------------------------+
| ConnectorBuild Write URL | http://c7-bzh3anilpx.gcp.postgres.ndc.internal/deployment/240ec317-ac19-4e87-9bcc-2b8f348f9b0a-write |
+--------------------------+------------------------------------------------------------------------------------------------------+
| Authorization Header     | Bearer Q2ceb6OjFGGpkoWMkt2JsWHRjMpJ5lmEGpORwhVHgVg=                                                  |
+--------------------------+------------------------------------------------------------------------------------------------------+
```

The read and write URLs and authorization header will be written to the `.env.cloud` file.

### Step 2. Other Data Domain Teams: Initialize their subgraphs

Each data domain team (like "Products" or "Reviews") should initialize their own project and create a stub
DataConnectorLink:

```sh
ddn supergraph init products-project
cd products-project
```

### Step 3. Other Data Domain Teams: Use the deployed connector

It is now not necesary for each data domain team to have the database connection string in their subgraph.

Each data domain team should obtain two things from the connector deployment repository:

1. The schema object from the `DataConnectorLink` from the connector repository
2. The read and write URLs from the `.env.cloud` file from the team that deployed the connector

#### Step 3.1

```sh
ddn connector init my_postgres --hub-connector hasura/postgres
```

This will create a stub `DataConnectorLink` object in their project.

#### Step 3.2

Copy the `DataConnectorLink` object from the connector repository's `app/metadata/my_postgres.hml` file and replace it
in your team's `app/metadata/my_postgres.hml` file. This contains the database structure and capabilities.

#### Step 3.3

Now you can introspect and add the models, commands, and relationships which you need for your specific use case:

```sh
ddn connector show-resources my_postgres
ddn model add my_postgres "*"
ddn command add my_postgres "*"
ddn relationship add my_postgres "*"
```

#### Step 3.4

Initialize the project:

```sh
ddn project init
```

#### Step 3.5

Then, replace the connector URLs, authorization header and service token secret in your team's `.env.cloud` file with
the values from the connector repository:

```env
APP_MY_POSTGRES_AUTHORIZATION_HEADER="Bearer <authorization-header>"
APP_MY_POSTGRES_READ_URL="http://<build-id>.gcp.postgres.ndc.internal/deployment/<uuid>-read"
APP_MY_POSTGRES_WRITE_URL="http://<build-id>.gcp.postgres.ndc.internal/deployment/<uuid>-write"
APP_MY_POSTGRES_HASURA_SERVICE_TOKEN_SECRET="<hasura-service-token-secret>"
```

### Step 4. Data Domain Teams: Build and deploy their supergraphs

Each team can then build their supergraph without rebuilding the connector and deploy it to their DDN project:

```sh
ddn supergraph build create --no-build-connectors
```

The `--no-build-connectors` flag is crucial here as it tells DDN to use the existing connector URLs rather than trying
to deploy a new connector instance.

### Step 5. Repeat for other subgraphs and projects

These teams can repeat these steps for any other subgraphs or projects that need access to the same PostgreSQL database.

## Example scenario: Private DDN

For Private DDN, the process differs slightly as you're working within a private data plane environment. This approach
is ideal for Enterprise users who must maintain data sovereignty and security.

### Step 1: Create a Service Account for secure connector access

Before creating a reusable connector, you should create a Service Account that will be used to authenticate access to
the connector:

1. As a project owner or administrator, navigate to your project's console at
   [https://console.hasura.io](https://console.hasura.io)
2. Click `Settings` in the bottom-left corner
3. Select `Service Accounts` from the `Project Settings` menu and click `New Service Account`
4. Enter a name for the service account (for example, "postgres-connector-access")
5. After creating the service account, copy the service account token and store it securely - you will need it later

### Step 2: Create and deploy a connector on your Private Data Plane

First, authenticate with your Private DDN either directly or using the DDN Workspace:

```sh
# If using direct CLI
ddn auth login

# If using a service account token (recommended for automation)
ddn auth login --access-token <service-account-token>
```

Create a dedicated connector project and initialize your connector:

```sh
mkdir postgres-connector
cd postgres-connector
ddn supergraph init connector-project
cd connector-project
ddn connector init -i
```

After configuring your connector, create a project on your private data plane:

```sh
ddn project init --data-plane-id <data-plane-id> --plan <plan-name>
```

Next, build and deploy the connector:

```sh
ddn connector build create --connector ./app/connector/mypostgres/connector.yaml --target-env-file ./.env.cloud  --target-subgraph ./app/subgraph.yaml --target-connector-link mypostgres
```

The command will output the connector's read and write URLs and the authorization header, which will also be stored in
your `.env.cloud` file.

### Step 3: Teams share connector using Service Account Token

To securely share the connector across teams and projects within your Private DDN, you should share:

1. The schema object from the DataConnectorLink
2. The read and write URLs from the `.env.cloud` file
3. The Service Account Token (set as the authorization header)

When a team wants to use the shared connector, they'll add the following to their `.env.cloud` file:

```env
# For a PostgreSQL connector named "mypostgres"
APP_MYPOSTGRES_AUTHORIZATION_HEADER="Bearer <service-account-token>"
APP_MYPOSTGRES_READ_URL="http://<build-id>.<private-data-plane-domain>/deployment/<uuid>-read"
APP_MYPOSTGRES_WRITE_URL="http://<build-id>.<private-data-plane-domain>/deployment/<uuid>-write"
```

:::warning Security Note

The Service Account Token should be treated as a secret. In production environments, use your organization's secrets
management system to securely distribute and rotate this token as needed.

:::

### Step 4: Teams use the connector in their subgraphs

Each team can initialize their own project on the same Private Data Plane:

```sh
ddn project init --data-plane-id <data-plane-id> --plan <plan-name>
```

Then create a connector link and configure it to use the shared connector:

```sh
ddn connector-link add my_postgres
```

They'll need to copy the schema object from the original connector repository's DataConnectorLink into their team's
DataConnectorLink. Then they can customize the models, commands, and relationships for their specific use case:

```sh
ddn connector show-resources my_postgres
ddn connector models add "*"
ddn connector commands add "*"
ddn connector relationships add "*"
```

### Step 5: Build and deploy subgraphs without rebuilding connectors

Teams can then build their subgraphs without rebuilding the connector:

```sh
ddn supergraph build create --no-build-connectors
```

## Considerations

- **Versioning:** If the connector is updated you may need to update the metadata for all subgraphs that use it.
  Coordinate updates carefully.

- **Regionality:** Deploying the connector in a region close to your database is crucial for performance. If different
  subgraphs have different latency requirements, consider deploying separate connectors closer to their respective
  consumers.

- **Central point of failure:** All subgraphs (and projects) using a single connector, will be impacted if this
  connector is down.

- **Independent Management:** Having a dedicated connector repository allows you to manage connector updates and
  deployments independently of the data domain teams' development cycles.

- **Service Account Security:** In Private DDN environments, regularly rotate your service account tokens and follow
  your organization's security best practices for token management.

- **Access Control:** In Private DDN, ensure that only authorized teams have access to the service account tokens needed
  to access shared connectors.

## Summary

Connector reusability in Hasura DDN offers a way to reduce redundancy and simplify management of connector deployments.
By using a dedicated repository for connector deployment, you can better manage connector updates and ensure consistent
access across multiple teams and projects. For Private DDN users, this approach provides additional security benefits
while still enabling efficient connector sharing.

For a list of all our available connectors, check out the [docs](/data-sources/overview.mdx).
