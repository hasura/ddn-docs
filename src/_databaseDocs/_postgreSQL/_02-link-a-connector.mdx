import BaseUrlLink from '@site/src/_databaseDocs/baseLink';

## What's about to happen?

After initting a connector and creating a JSON configuration, which represents our tables in PostgreSQL, we can use it
to generate Hasura metadata. In the steps below, we'll utilize our `configuration.json` â€” populated by introspecting our
PostgreSQL database â€” to create metadata which Hasura can use to construct our API.

## Step 1. Create the Hasura metadata

:::tip Required

- <BaseUrlLink to="/getting-started/prerequisites" text="DDN CLI" />
- A new or existing <BaseUrlLink to="/getting-started/init-supergraph" text="supergraph" />
- A new or existing <BaseUrlLink to="/getting-started/init-subgraph" text="subgraph" />
- A <BaseUrlLink to="/getting-started/connect-to-data/connect-a-source" text="PostgreSQL connector"/> initted

:::

<!-- prettier-ignore -->
Hasura DDN uses a concept called "connector linking" to take [NDC-compliant](https://github.com/hasura/ndc-spec)
configuration JSON files for a data connector and transform them into an `hml` (Hasura Metadata Language) file as a <BaseUrlLink to="/supergraph-modeling/data-connectors/" text="DataConnectorLink" /> metadata object.

Basically, metadata objects in `hml` files define our API.

First we need to create this `hml` file with the `connector-link add` command and then convert our configuration files
into `hml` syntax and add it to this file with the `connector-link update` command.

Let's name the `hml` file the same as our connector, `mypg`:

```bash
ddn connector-link add mypg
```

The new file is scaffolded out at `<subgraph-name>/metadata/mypg/mypg.hml`.

<details>
  <summary>Click here for an example `hml` `DataConnectorLink` file</summary>

```yaml
kind: DataConnectorLink
version: v1
definition:
name: mypg
url:
  readWriteUrls:
    read:
      valueFromEnv: MY_SUBGRAPH_MYPG_READ_URL
    write:
      valueFromEnv: MY_SUBGRAPH_MYPG_WRITE_URL
schema:
  version: v0.1
  schema:
    scalar_types: {}
    object_types: {}
    collections: []
    functions: []
    procedures: []
  capabilities:
    version: ''
    capabilities:
      query: {}
      mutation: {}
```

</details>

The generated file has two environment variables â€” one for reads and one for writes â€”Â that you'll need to add to your
subgraph's `.env` file. As with the example we've followed so far, if we have a subgraph of `ux`, we'll need to add the
following snippet to our `ux/.env.ux` file:

```env
UX_MYPG_READ_URL=http://local-dev.hasura.me:8081
UX_MYPG_WRITE_URL=http://local-dev.hasura.me:8081
```

These values are for the PostgreSQL connector itself and utilize `local-dev.hasura.me` to ensure proper resolution
within the docker container.

## Step 2. Update the new DataConnectorLink object

Finally, now that our `DataConnectorLink` has the correct environment variables configured for the PostgreSQL connector,
we can run the update command to have the CLI look at the configuration JSON and transform it to reflect our database's
schema in `hml` format:

```bash
ddn connector-link update mypg --subgraph <subgraph-name>
```

After this command runs, you can open your `<subgraph>/connector/mypg/metadata/mypg/mypg.hml` file and see your metadata
completely scaffolded out for you ðŸŽ‰

## What did this do?

<!-- prettier-ignore -->
By creating a `mypg.hml` file, we've provided Hasura with a link between our original data source and the types which
we'll eventually expose via our API.

## Next steps

With a data connector fully configured, you can now start to create metadata for each table and view in your PostgreSQL
database using `hml`. Learn how to do this by

<BaseUrlLink to="/getting-started/connect-to-data/expose-source-entities" text="exposing source entities" />.
